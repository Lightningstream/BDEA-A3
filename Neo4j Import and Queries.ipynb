{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CREATE File from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neo4j\n",
      "  Downloading neo4j-5.9.0.tar.gz (188 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from neo4j) (2023.3)\n",
      "Building wheels for collected packages: neo4j\n",
      "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neo4j: filename=neo4j-5.9.0-py3-none-any.whl size=259467 sha256=2b6a8d8aee2b2f21069d622adf7861f0becddabe2ac76c1309a5946034de4fd9\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/5a/6a/b3/89ab0efac04cf204cfc65f2bff4776865cfe5ff2e1b94ebaff\n",
      "Successfully built neo4j\n",
      "Installing collected packages: neo4j\n",
      "Successfully installed neo4j-5.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Neo4jConnection(uri=\"bolt://graph_db:7687\", user=\"neo4j\", pwd=\"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_file = open('twitter_combined.txt', 'r')\n",
    "lines = follows_file.readlines()\n",
    "\n",
    "follows = []\n",
    "users = set()\n",
    "for line in lines:\n",
    "    line = line.replace('\\n','')\n",
    "    id1, id2 = line.split(' ')\n",
    "    users.add(id1)\n",
    "    users.add(id2)\n",
    "    follows.append([id1, id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"tweets.csv\")\n",
    "f = open(\"import/tweetsDB.csv\", \"w\")\n",
    "writer = csv.writer(f)\n",
    "writer.writerow([\"tweetId\",\"content\",\"date_time\",\"language\",\":Label\"])\n",
    "count = 1\n",
    "for index, tweet in tweets.iterrows():\n",
    "    writer.writerow([count,tweet[\"content\"],tweet[\"date_time\"],tweet[\"language\"],\"TWEET\"])\n",
    "    count += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "f = open(\"import/users.csv\", \"w\")\n",
    "f.write(\"userId,name,:Label\\n\")\n",
    "for user in users:\n",
    "   f.write(user + \",user\" + str(count) + \",USER\\n\")\n",
    "   count += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"import/follows.csv\", \"w\")\n",
    "f.write(\"userId,followerId,:TYPE\\n\")\n",
    "for follow in follows:\n",
    "    f.write(follow[0] + \",\" + follow[1] + \",FOLLOWS\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record n=<Node element_id='4:e1a2f8d3-a31f-446e-9e94-2a84f08f0ca3:0' labels=frozenset({'User'}) properties={'name': 'user0', 'userId': '16404379'}>>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(f\"MATCH (n) RETURN n LIMIT 1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: {code: Neo.ClientError.Schema.ConstraintValidationFailed} {message: Node(61845) already exists with label `User` and property `userId` = '9003112' (Failure when processing file '/var/lib/neo4j/import/users.csv' on line 2.)}\n",
      "Query failed: {code: Neo.ClientError.Schema.ConstraintValidationFailed} {message: Node(81306) already exists with label `Tweet` and property `tweetId` = '1' (Failure when processing file '/var/lib/neo4j/import/tweetsDB.csv' on line 2.)}\n"
     ]
    }
   ],
   "source": [
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///users.csv' AS row CREATE (:User {userId: row.userId, name: row.name})\")\n",
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///tweetsDB.csv' AS row CREATE (:Tweet {tweetId: row.tweetId, content: row.content, date_time: row.date_time, language: row.language})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(\"CREATE CONSTRAINT user_constraint IF NOT EXISTS FOR (u:User) REQUIRE u.userId IS UNIQUE\")\n",
    "conn.query(\"CREATE CONSTRAINT tweet_constraint IF NOT EXISTS FOR (t:Tweet) REQUIRE t.tweetId IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///follows.csv' AS row MATCH (e:User {userId: row.userId}) MATCH (c:User {userId: row.followerId}) MERGE (e)-[:FOLLOWS]->(c)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = conn.query(\"MATCH (a)-[:FOLLOWS]->(b) RETURN b, COUNT(a) as followers ORDER BY followers DESC LIMIT 100\")\n",
    "user_ids = []\n",
    "for record in top100:\n",
    "    user_ids.append(record.get(\"b\").get(\"userId\"))\n",
    "\n",
    "tweets = pd.read_csv(\"import/tweetsDB.csv\")\n",
    "f = open(\"import/posted.csv\", \"w\")\n",
    "f.write(\"userId,tweetId,:TYPE\\n\")\n",
    "for index, tweet in tweets.iterrows():\n",
    "    f.write(f'{random.choice(user_ids)},{tweet[\"tweetId\"]},POSTED\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///posted.csv' AS row MATCH (u:User {userId: row.userId}) MATCH (t:Tweet {tweetId: row.tweetId}) MERGE (u)-[:POSTED]->(t)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = conn.query(\"MATCH (a)-[:FOLLOWS]->(b) RETURN b, COUNT(a) as followers ORDER BY followers DESC LIMIT 100\")\n",
    "allTweets = conn.query(\"Match (t: Tweet) RETURN t\");\n",
    "f = open(\"import/likes.csv\",\"w\")\n",
    "f.write(\"userId,tweetId,:TYPE\\n\")\n",
    "\n",
    "for user in top100: \n",
    "    followers = conn.query(f\"MATCH (follower:User)-[:FOLLOWS]->(following:User) WHERE following.userId ='{user['b']['userId']}' RETURN follower\")\n",
    "    tweets = conn.query(f\"MATCH (u:User {{userId: '{user['b']['userId']}'}})-[:POSTED]->(t:Tweet) RETURN t\");\n",
    "    for tweet in tweets: \n",
    "        for follower in followers:\n",
    "            shouldLike = random.random() < 0.1\n",
    "            if shouldLike:\n",
    "                f.write(f\"{follower['follower']['userId']},{tweet['t']['tweetId']},LIKES\\n\")\n",
    "\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///likes.csv' as row CALL { with row MATCH (u:User {userId: row.userId}) MATCH (t:Tweet {tweetId: row.tweetId}) MERGE (u)-[:LIKES]->(t) }  IN TRANSACTIONS OF 100000 ROWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 User mit den meisten Followern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user23516 hat 3383 Follower\n",
      "user25074 hat 3216 Follower\n",
      "user1781 hat 2735 Follower\n",
      "user50940 hat 2647 Follower\n",
      "user69469 hat 2471 Follower\n",
      "user40743 hat 2462 Follower\n",
      "user33433 hat 2133 Follower\n",
      "user38752 hat 2074 Follower\n",
      "user14303 hat 1905 Follower\n",
      "user29918 hat 1707 Follower\n",
      "user73980 hat 1632 Follower\n",
      "user31252 hat 1591 Follower\n",
      "user56892 hat 1521 Follower\n",
      "user56971 hat 1503 Follower\n",
      "user66477 hat 1500 Follower\n",
      "user77339 hat 1410 Follower\n",
      "user77394 hat 1402 Follower\n",
      "user4665 hat 1370 Follower\n",
      "user21904 hat 1337 Follower\n",
      "user58114 hat 1315 Follower\n",
      "user47959 hat 1273 Follower\n",
      "user45639 hat 1255 Follower\n",
      "user71012 hat 1231 Follower\n",
      "user19416 hat 1214 Follower\n",
      "user1733 hat 1201 Follower\n",
      "user18127 hat 1198 Follower\n",
      "user58309 hat 1186 Follower\n",
      "user52387 hat 1167 Follower\n",
      "user63035 hat 1154 Follower\n",
      "user27752 hat 1123 Follower\n",
      "user77284 hat 1120 Follower\n",
      "user64715 hat 1108 Follower\n",
      "user33440 hat 1098 Follower\n",
      "user77008 hat 1088 Follower\n",
      "user76017 hat 1072 Follower\n",
      "user80101 hat 1070 Follower\n",
      "user10026 hat 1059 Follower\n",
      "user19035 hat 1053 Follower\n",
      "user60306 hat 1047 Follower\n",
      "user11550 hat 1036 Follower\n",
      "user41077 hat 1022 Follower\n",
      "user65544 hat 1016 Follower\n",
      "user23821 hat 1014 Follower\n",
      "user31073 hat 992 Follower\n",
      "user54692 hat 989 Follower\n",
      "user35681 hat 977 Follower\n",
      "user40788 hat 957 Follower\n",
      "user74879 hat 928 Follower\n",
      "user25302 hat 920 Follower\n",
      "user115 hat 915 Follower\n",
      "user27502 hat 915 Follower\n",
      "user77805 hat 913 Follower\n",
      "user24501 hat 911 Follower\n",
      "user47582 hat 900 Follower\n",
      "user38931 hat 894 Follower\n",
      "user66649 hat 889 Follower\n",
      "user34800 hat 884 Follower\n",
      "user35707 hat 865 Follower\n",
      "user3735 hat 859 Follower\n",
      "user74324 hat 852 Follower\n",
      "user44608 hat 852 Follower\n",
      "user79737 hat 844 Follower\n",
      "user62554 hat 839 Follower\n",
      "user21154 hat 831 Follower\n",
      "user74556 hat 818 Follower\n",
      "user61486 hat 813 Follower\n",
      "user53515 hat 793 Follower\n",
      "user76560 hat 786 Follower\n",
      "user3786 hat 784 Follower\n",
      "user61335 hat 778 Follower\n",
      "user12390 hat 761 Follower\n",
      "user70373 hat 754 Follower\n",
      "user47646 hat 750 Follower\n",
      "user5521 hat 750 Follower\n",
      "user73512 hat 750 Follower\n",
      "user4008 hat 749 Follower\n",
      "user3021 hat 747 Follower\n",
      "user41327 hat 743 Follower\n",
      "user21408 hat 743 Follower\n",
      "user74550 hat 738 Follower\n",
      "user72024 hat 737 Follower\n",
      "user55111 hat 736 Follower\n",
      "user19033 hat 736 Follower\n",
      "user275 hat 735 Follower\n",
      "user77864 hat 732 Follower\n",
      "user36233 hat 731 Follower\n",
      "user64371 hat 730 Follower\n",
      "user68699 hat 728 Follower\n",
      "user42799 hat 714 Follower\n",
      "user71040 hat 712 Follower\n",
      "user79423 hat 710 Follower\n",
      "user60891 hat 709 Follower\n",
      "user78019 hat 697 Follower\n",
      "user69670 hat 683 Follower\n",
      "user3856 hat 679 Follower\n",
      "user69248 hat 672 Follower\n",
      "user44466 hat 672 Follower\n",
      "user8644 hat 669 Follower\n",
      "user24659 hat 666 Follower\n",
      "user63334 hat 665 Follower\n"
     ]
    }
   ],
   "source": [
    "top100 = conn.query(\"MATCH (a)-[:FOLLOWS]->(b) RETURN b, COUNT(a) as followers ORDER BY followers DESC LIMIT 100\")\n",
    "\n",
    "for user in top100:\n",
    "    print(user['b']['name'], \"hat\", user['followers'], \"Follower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 User, die den meisten Userns der Top 100 folgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"MATCH (follower:User)-[follows:FOLLOWS]->(followed:User)\n",
    "WHERE followed.userId IN [\"\"\" \n",
    "\n",
    "count = 0\n",
    "for user in top100:\n",
    "    query += f\"'{user['b']['userId']}'\"\n",
    "    if count < 99: query += \",\"\n",
    "    count += 1\n",
    "\n",
    "query += \"\"\"]\n",
    "WITH follower, COUNT(follows) AS numFollowed\n",
    "ORDER BY numFollowed DESC\n",
    "RETURN follower.name AS username, numFollowed\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "result = conn.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user14303 folgt 69 Usern\n",
      "user41327 folgt 55 Usern\n",
      "user2169 folgt 50 Usern\n",
      "user41320 folgt 49 Usern\n",
      "user33440 folgt 47 Usern\n",
      "user64029 folgt 46 Usern\n",
      "user29265 folgt 44 Usern\n",
      "user38908 folgt 41 Usern\n",
      "user29314 folgt 40 Usern\n",
      "user36591 folgt 39 Usern\n",
      "user12499 folgt 38 Usern\n",
      "user33065 folgt 38 Usern\n",
      "user74270 folgt 37 Usern\n",
      "user21544 folgt 37 Usern\n",
      "user51566 folgt 37 Usern\n",
      "user29427 folgt 36 Usern\n",
      "user67590 folgt 35 Usern\n",
      "user71341 folgt 35 Usern\n",
      "user66389 folgt 35 Usern\n",
      "user41077 folgt 35 Usern\n",
      "user61428 folgt 34 Usern\n",
      "user38931 folgt 34 Usern\n",
      "user46348 folgt 34 Usern\n",
      "user64184 folgt 34 Usern\n",
      "user12403 folgt 34 Usern\n",
      "user37319 folgt 34 Usern\n",
      "user76560 folgt 33 Usern\n",
      "user31252 folgt 33 Usern\n",
      "user3856 folgt 33 Usern\n",
      "user68699 folgt 33 Usern\n",
      "user78174 folgt 31 Usern\n",
      "user20319 folgt 31 Usern\n",
      "user4283 folgt 31 Usern\n",
      "user11039 folgt 31 Usern\n",
      "user54856 folgt 31 Usern\n",
      "user34702 folgt 30 Usern\n",
      "user29803 folgt 30 Usern\n",
      "user48178 folgt 30 Usern\n",
      "user21179 folgt 30 Usern\n",
      "user1733 folgt 30 Usern\n",
      "user24086 folgt 30 Usern\n",
      "user73512 folgt 29 Usern\n",
      "user72950 folgt 29 Usern\n",
      "user26324 folgt 29 Usern\n",
      "user25095 folgt 29 Usern\n",
      "user59825 folgt 29 Usern\n",
      "user6668 folgt 29 Usern\n",
      "user45330 folgt 28 Usern\n",
      "user66649 folgt 28 Usern\n",
      "user41345 folgt 28 Usern\n",
      "user77284 folgt 28 Usern\n",
      "user51021 folgt 28 Usern\n",
      "user54709 folgt 28 Usern\n",
      "user14291 folgt 28 Usern\n",
      "user81022 folgt 27 Usern\n",
      "user29675 folgt 27 Usern\n",
      "user53386 folgt 27 Usern\n",
      "user61829 folgt 27 Usern\n",
      "user13672 folgt 27 Usern\n",
      "user77394 folgt 27 Usern\n",
      "user61335 folgt 27 Usern\n",
      "user55891 folgt 27 Usern\n",
      "user34618 folgt 27 Usern\n",
      "user45745 folgt 27 Usern\n",
      "user786 folgt 27 Usern\n",
      "user3414 folgt 27 Usern\n",
      "user18095 folgt 26 Usern\n",
      "user14755 folgt 26 Usern\n",
      "user23821 folgt 26 Usern\n",
      "user78 folgt 26 Usern\n",
      "user31918 folgt 26 Usern\n",
      "user16279 folgt 26 Usern\n",
      "user59746 folgt 26 Usern\n",
      "user40788 folgt 26 Usern\n",
      "user15832 folgt 26 Usern\n",
      "user9204 folgt 26 Usern\n",
      "user10698 folgt 26 Usern\n",
      "user74462 folgt 25 Usern\n",
      "user16401 folgt 25 Usern\n",
      "user63690 folgt 25 Usern\n",
      "user45603 folgt 25 Usern\n",
      "user67336 folgt 25 Usern\n",
      "user50589 folgt 25 Usern\n",
      "user39028 folgt 25 Usern\n",
      "user60340 folgt 25 Usern\n",
      "user25283 folgt 25 Usern\n",
      "user65954 folgt 25 Usern\n",
      "user10987 folgt 25 Usern\n",
      "user8475 folgt 25 Usern\n",
      "user71689 folgt 25 Usern\n",
      "user46963 folgt 25 Usern\n",
      "user16488 folgt 25 Usern\n",
      "user25264 folgt 25 Usern\n",
      "user70901 folgt 24 Usern\n",
      "user71202 folgt 24 Usern\n",
      "user275 folgt 24 Usern\n",
      "user35044 folgt 24 Usern\n",
      "user65176 folgt 24 Usern\n",
      "user10210 folgt 24 Usern\n",
      "user80357 folgt 24 Usern\n"
     ]
    }
   ],
   "source": [
    "for record in result:\n",
    "    print(record['username'], \"folgt\", record['numFollowed'], 'Usern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alle Posts eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_user = random.choice(top100)\n",
    "\n",
    "result = conn.query(f\"MATCH (u:User {{name: '{random_user['b']['name']}'}})-[:POSTED]->(t:Tweet) RETURN t\")\n",
    "for tweet in result:\n",
    "    continue\n",
    "    #print(tweet['t']['content'])\n",
    "    #print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anzahl der Follower eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(f\"MATCH (follower:User)-[:FOLLOWS]->(user:User {{name: '{random_user['b']['name']}'}}) RETURN count(follower) AS followerCount\")\n",
    "print(result[0]['followerCount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anzahl der verfolgten Accounts eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(f\"MATCH (user:User {{name: '{random_user['b']['name']}'}})-[:FOLLOWS]->(followed:User) RETURN count(followed) AS followedCount\")\n",
    "print(result[0]['followedCount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die 25 meistgeliketen Posts der gefolgten Accounts eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Roots album avail now!! \n",
      "https://t.co/rJdXrSyYr5‚Ä¶ http://t.co/fYjdt2dxN8\n",
      "Likes:  3668\n",
      "\n",
      "@tariqterry bb I travel\n",
      "Likes:  3507\n",
      "\n",
      "Eu tento responder a quantas posso. @babihsd @Cristiano perdi a sess√£o de perguntas e respostas? N√£o creio! Faz de novo!\n",
      "Likes:  3501\n",
      "\n",
      "We‚Äôll have the Santa Roll with a side of Miso. https://t.co/npP7r4j1Ms https://t.co/MQlhBx32WH\n",
      "Likes:  3474\n",
      "\n",
      ".@skyferreira's setting the world record for use of lazers on our show tonight. Tune in. #FallonTonight\n",
      "Likes:  3447\n",
      "\n",
      "üí≠ http://t.co/9Q6v0Znn4N\n",
      "Likes:  3399\n",
      "\n",
      "I saved a piece of birthday cake my fans. You made my 20s worth it all.  To spreading love, above all things. ‚ù§Ô∏èüåé https://t.co/69Z2JX4ylt\n",
      "Likes:  3387\n",
      "\n",
      "So interesting. @BillGates is on our program this evening. Fun. #GatesLetterDOTCOM\n",
      "Likes:  3132\n",
      "\n",
      "Let me hear u #ScreamingAndShouting with tweets if u downloaded the song on iTunes... feeling it people?? http://t.co/kaRLNR2W\n",
      "Likes:  3058\n",
      "\n",
      "Lady Gaga and @ladystarlightny raid the floors of #affleckspalace  We've been a duo for almost 10‚Ä¶ http://t.co/dYa9hrNUyn\n",
      "Likes:  2928\n",
      "\n",
      "Roses. http://t.co/NWBJF03C7W\n",
      "Likes:  2856\n",
      "\n",
      "What a great day at the skate park looks like!! Thanks @AlexMidler @Volcom @RealSkateboards for making it so special! http://t.co/frvbKb9gkl\n",
      "Likes:  2850\n",
      "\n",
      "‚ÄúEvery time I look at one of the drawings, they make me smile, and I think we need more of that.‚Äù ‚Äî@MarieMcG23 https://t.co/KOWVfW0vzQ\n",
      "Likes:  2841\n",
      "\n",
      "Made buckwheat crepes this morning (and by morning, I mean 1pm when I woke up) http://t.co/AdiYY2dg\n",
      "Likes:  2829\n",
      "\n",
      "I üíó you @maryjblige!!\n",
      "Likes:  2808\n",
      "\n",
      "I'm SO POWERED UP #artRAVESeoul get ready to rage tonight! üíé &amp; üíä\n",
      "Likes:  2799\n",
      "\n",
      "Playing \"Word Sneak\" with the hilarious Martin Short http://t.co/6QRSoZRrlu #FallonTonight\n",
      "Likes:  2796\n",
      "\n",
      "I've done everything I could to the best of my ability. Thank you for the unconditional love and cyber‚Ä¶ http://t.co/Q4LLTjuOVL\n",
      "Likes:  2787\n",
      "\n",
      "The Week on Instagram | 209 \n",
      "https://t.co/uBAxE1fBfs https://t.co/WNIObsuX34\n",
      "Likes:  2781\n",
      "\n",
      "A fire broke out Monday at Florida mosque where the Pulse nightclub shooter, Omar Mateen, used to pray. https://t.co/0d4PZ6Nxu0\n",
      "Likes:  2772\n",
      "\n",
      "Happy birthday, @JimmyFallon! I had so much fun beating you in our lip sync battle. B!@#$ better have my trophy. Sending love.\n",
      "Likes:  2763\n",
      "\n",
      "Thank you for the Trend Monsters, was really sweet. üíó Resting up for the show tonight. ArtRave #44 and dreaming of Tony and #cheektocheek\n",
      "Likes:  2751\n",
      "\n",
      "Happy 4th of July, America!\n",
      "\n",
      "--The Timberlakes https://t.co/N6MPAEwFMo\n",
      "Likes:  2736\n",
      "\n",
      "Oh my goodness, still in shock from this AM. So cool!!! http://t.co/bUVGR9cCuA\n",
      "Likes:  2733\n",
      "\n",
      "@isayuhhi all day\n",
      "Likes:  2721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(f\"\"\"\n",
    "MATCH (follower:User)-[:FOLLOWS]->(followed:User)-[:POSTED]->(tweet:Tweet)\n",
    "WHERE follower.name = '{random_user['b']['name']}'\n",
    "WITH follower, collect(followed.name) AS followedUsers\n",
    "MATCH (t:Tweet)<-[:POSTED]-(u:User)\n",
    "WHERE u.name IN followedUsers\n",
    "OPTIONAL MATCH (t)<-[:LIKES]-(liker:User)\n",
    "RETURN t.content AS content, COUNT(liker) AS numLikes\n",
    "ORDER BY numLikes DESC\n",
    "LIMIT 25\n",
    "\"\"\")\n",
    "\n",
    "for tweet in result:\n",
    "    print(tweet['content'])\n",
    "    print(\"Likes: \", tweet['numLikes'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die 25 neuesten Posts der gefolgten Accounts eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÄúTo sit back and let fate play its hand out and never influence it is not the way man was meant to operate.‚Äù https://t.co/U7cUApqcz7\n",
      "Getweeted am:  31/12/2016 23:30\n",
      "\n",
      "\"Don‚Äôt count the days; make the days count.\" https://t.co/uiedUxLbg4\n",
      "Getweeted am:  31/12/2016 22:37\n",
      "\n",
      "Gracias a todos por regalarme un a√±o m√°s disfrutando de hacer m√∫sica y comparti√©ndola con ustedes! Mucha paz y aleg‚Ä¶ https://t.co/B7xJ7YNs7m\n",
      "Getweeted am:  31/12/2016 22:26\n",
      "\n",
      "\"Despite everything, no one can dictate who you are to other people.\" https://t.co/Vw9cZsFGqI\n",
      "Getweeted am:  31/12/2016 21:32\n",
      "\n",
      "peace 2016 \n",
      "and thank you ‚úåüèºÔ∏è\n",
      "‚òÑÔ∏èüôèüèº‚ô° \n",
      "we're gonna be alright üí´üí°\n",
      "‚ô° üêá https://t.co/WtuXfwutzU\n",
      "Getweeted am:  31/12/2016 20:38\n",
      "\n",
      "In 2016, #ThisHappened https://t.co/6pZjo8fylG\n",
      "Getweeted am:  31/12/2016 18:26\n",
      "\n",
      "In 2016, #ThisHappened https://t.co/6pZjo8fylG\n",
      "Getweeted am:  31/12/2016 18:26\n",
      "\n",
      "From Rio to Euro and everything in between. These were the most talked about trends around the globe in 2016.\n",
      "https://t.co/LQJNkKE8of\n",
      "Getweeted am:  31/12/2016 17:34\n",
      "\n",
      "From Rio to Euro and everything in between. These were the most talked about trends around the globe in 2016.\n",
      "https://t.co/LQJNkKE8of\n",
      "Getweeted am:  31/12/2016 17:34\n",
      "\n",
      "Who's got Chantaje on their @Spotify NYE playlist for tonight? Let us know where you‚Äôre partying! ShakHQ https://t.co/EAtARlrG6F\n",
      "Getweeted am:  31/12/2016 14:51\n",
      "\n",
      "#DailyFluff\n",
      "https://t.co/LUvfxwzfNl üêæ https://t.co/nyl0tkxdOG\n",
      "Getweeted am:  31/12/2016 12:03\n",
      "\n",
      "#DailyFluff\n",
      "https://t.co/LUvfxwzfNl üêæ https://t.co/nyl0tkxdOG\n",
      "Getweeted am:  31/12/2016 12:03\n",
      "\n",
      "you just got knocked the fuck out\n",
      "Getweeted am:  31/12/2016 06:23\n",
      "\n",
      "üéºüéºüéº YEEZY YEEZY YEEZY NEW SONG ABOUT TO DROP #FACTS üî•üî•üî•\n",
      "Getweeted am:  31/12/2015 23:58\n",
      "\n",
      "üéºüéºüéº YEEZY YEEZY YEEZY NEW SONG ABOUT TO DROP #FACTS üî•üî•üî•\n",
      "Getweeted am:  31/12/2015 23:58\n",
      "\n",
      "üéøthank you to our fans and loved ones who bless us with so much each year. We had a beautiful‚Ä¶ https://t.co/SRgCNbo2ob\n",
      "Getweeted am:  31/12/2015 23:13\n",
      "\n",
      "Ameowzing. Get it ‚Ä¶ aMEOWzing. Oh, Zing! https://t.co/7O5QKD8blT https://t.co/D0lcNw0xSa\n",
      "Getweeted am:  31/12/2015 23:00\n",
      "\n",
      "#RockinEve tonight!! Celebrate with #CONFIDENT on sale for a special price on @AppleMusic üòúüòú https://t.co/UFMTpIsceX https://t.co/Pgh5Y5PiXe\n",
      "Getweeted am:  31/12/2015 21:38\n",
      "\n",
      "NEW YEARS RESOLUTIONS https://t.co/A02mVD067O https://t.co/7zumq6T06S\n",
      "Getweeted am:  31/12/2015 21:30\n",
      "\n",
      "Our family group chat about our 2016 goals is giving me life!!!! #WatchOutWorld\n",
      "Getweeted am:  31/12/2015 20:44\n",
      "\n",
      "Praying for everyone in Dubai!\n",
      "Getweeted am:  31/12/2015 20:41\n",
      "\n",
      "grateful and excited. thank you to my babes for making 2015 so special. I love you I love you sfm. happy New Year's Eve!!!!!!!!!!!!!!!!!!! ‚ú®\n",
      "Getweeted am:  31/12/2015 19:25\n",
      "\n",
      "DEADLINE: Chip in to help fund the fight for more progress in 2016. https://t.co/ezVFTh8LJ2\n",
      "Getweeted am:  31/12/2015 19:24\n",
      "\n",
      "DEADLINE: Chip in to help fund the fight for more progress in 2016. https://t.co/ezVFTh8LJ2\n",
      "Getweeted am:  31/12/2015 19:24\n",
      "\n",
      "Just thought of another New Years resolution.I really want to make my moms life easier &amp; be extra nice! She's the best &amp;does everything 4 us\n",
      "Getweeted am:  31/12/2015 17:05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(f\"\"\"\n",
    "MATCH (follower:User)-[:FOLLOWS]->(followed:User)-[:POSTED]->(tweet:Tweet)\n",
    "WHERE follower.name = '{random_user['b']['name']}'\n",
    "WITH follower, collect(followed.name) AS followedUsers\n",
    "MATCH (t:Tweet)<-[:POSTED]-(u:User)\n",
    "WHERE u.name IN followedUsers\n",
    "RETURN t.content AS content, t.date_time AS date\n",
    "ORDER BY t.date_time DESC\n",
    "LIMIT 25\n",
    "\"\"\")\n",
    "\n",
    "for tweet in result:\n",
    "    print(tweet['content'])\n",
    "    print(\"Getweeted am: \", tweet['date'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching / Fan Out hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die 25 beliebtesten Tweets, die die W√∂rter \"hello\" und \"from\" enthalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did @Adele cross the road? She wanted to say hello from the other side.\n",
      "Likes:  1022\n",
      "\n",
      "You asked: \n",
      "Hello from Japan!\n",
      "I'm Anna!I I'm a big fan! Please say me hello Anna!\n",
      " http://t.co/5Oyi7SiUhY\n",
      "Likes:  394\n",
      "\n",
      "You asked: Can you say hello to me ,please? I am from Bulgaria!!! http://t.co/dyNj55sAq4\n",
      "Likes:  337\n",
      "\n",
      "You asked: Can you say hello to me?  My name is Narin and I am from Germany http://t.co/lx2CRb3xwh\n",
      "Likes:  214\n",
      "\n",
      "#JoanneVibes say hello from backstage at...??? https://t.co/m9PI2oUUo8\n",
      "Likes:  120\n",
      "\n",
      "Say hello to Himanshu Yadav and all my friends from #India. I will come shortly with more news. http://t.co/60xEW67c\n",
      "Likes:  98\n",
      "\n",
      "You asked: Hi Ronaldo! I love you so much! Please say hello to me! I am from Turkey!  http://t.co/xpDH5Ppb67\n",
      "Likes:  87\n",
      "\n",
      "You asked: hello from France, champion ! :) im so proud of you http://t.co/AhDl5iMGzF\n",
      "Likes:  83\n",
      "\n",
      "You asked: hello from morocco \n",
      " http://t.co/gbuEyP5953\n",
      "Likes:  79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(\"\"\"\n",
    "MATCH (t:Tweet)\n",
    "WHERE ALL(word IN [' hello ', ' from '] WHERE t.content CONTAINS word)\n",
    "WITH t\n",
    "MATCH (t)<-[:LIKES]-(liker:User)\n",
    "RETURN t.content AS content, COUNT(liker) AS numLikes\n",
    "ORDER BY numLikes DESC\n",
    "LIMIT 25\n",
    "\"\"\")\n",
    "\n",
    "for tweet in result:\n",
    "    print(tweet['content'])\n",
    "    print(\"Likes: \", tweet['numLikes'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
