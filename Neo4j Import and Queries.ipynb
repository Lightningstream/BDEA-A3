{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating CREATE File from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neo4j\n",
      "  Downloading neo4j-5.9.0.tar.gz (188 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from neo4j) (2023.3)\n",
      "Building wheels for collected packages: neo4j\n",
      "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neo4j: filename=neo4j-5.9.0-py3-none-any.whl size=259467 sha256=2b6a8d8aee2b2f21069d622adf7861f0becddabe2ac76c1309a5946034de4fd9\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/5a/6a/b3/89ab0efac04cf204cfc65f2bff4776865cfe5ff2e1b94ebaff\n",
      "Successfully built neo4j\n",
      "Installing collected packages: neo4j\n",
      "Successfully installed neo4j-5.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Neo4jConnection(uri=\"bolt://graph_db:7687\", user=\"neo4j\", pwd=\"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "follows_file = open('twitter_combined.txt', 'r')\n",
    "lines = follows_file.readlines()\n",
    "\n",
    "follows = []\n",
    "users = set()\n",
    "for line in lines:\n",
    "    line = line.replace('\\n','')\n",
    "    id1, id2 = line.split(' ')\n",
    "    users.add(id1)\n",
    "    users.add(id2)\n",
    "    follows.append([id1, id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"tweets.csv\")\n",
    "f = open(\"import/tweetsDB.csv\", \"w\")\n",
    "writer = csv.writer(f)\n",
    "writer.writerow([\"tweetId\",\"content\",\"date_time\",\"language\",\":Label\"])\n",
    "count = 1\n",
    "for index, tweet in tweets.iterrows():\n",
    "    writer.writerow([count,tweet[\"content\"],tweet[\"date_time\"],tweet[\"language\"],\"TWEET\"])\n",
    "    count += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "f = open(\"import/users.csv\", \"w\")\n",
    "f.write(\"userId,name,:Label\\n\")\n",
    "for user in users:\n",
    "   f.write(user + \",user\" + str(count) + \",USER\\n\")\n",
    "   count += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"import/follows.csv\", \"w\")\n",
    "f.write(\"userId,followerId,:TYPE\\n\")\n",
    "for follow in follows:\n",
    "    f.write(follow[0] + \",\" + follow[1] + \",FOLLOWS\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record n=<Node element_id='4:e1a2f8d3-a31f-446e-9e94-2a84f08f0ca3:0' labels=frozenset({'User'}) properties={'name': 'user0', 'userId': '16404379'}>>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(f\"MATCH (n) RETURN n LIMIT 1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: {code: Neo.ClientError.Schema.ConstraintValidationFailed} {message: Node(61845) already exists with label `User` and property `userId` = '9003112' (Failure when processing file '/var/lib/neo4j/import/users.csv' on line 2.)}\n",
      "Query failed: {code: Neo.ClientError.Schema.ConstraintValidationFailed} {message: Node(81306) already exists with label `Tweet` and property `tweetId` = '1' (Failure when processing file '/var/lib/neo4j/import/tweetsDB.csv' on line 2.)}\n"
     ]
    }
   ],
   "source": [
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///users.csv' AS row CREATE (:User {userId: row.userId, name: row.name})\")\n",
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///tweetsDB.csv' AS row CREATE (:Tweet {tweetId: row.tweetId, content: row.content, date_time: row.date_time, language: row.language})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(\"CREATE CONSTRAINT user_constraint IF NOT EXISTS FOR (u:User) REQUIRE u.userId IS UNIQUE\")\n",
    "conn.query(\"CREATE CONSTRAINT tweet_constraint IF NOT EXISTS FOR (t:Tweet) REQUIRE t.tweetId IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///follows.csv' AS row MATCH (e:User {userId: row.userId}) MATCH (c:User {userId: row.followerId}) MERGE (e)-[:FOLLOWS]->(c)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = conn.query(\"MATCH (a)-[:FOLLOWS]->(b) RETURN b, COUNT(a) as followers ORDER BY followers DESC LIMIT 100\")\n",
    "user_ids = []\n",
    "for record in top100:\n",
    "    user_ids.append(record.get(\"b\").get(\"userId\"))\n",
    "\n",
    "tweets = pd.read_csv(\"import/tweetsDB.csv\")\n",
    "f = open(\"import/posted.csv\", \"w\")\n",
    "f.write(\"userId,tweetId,:TYPE\\n\")\n",
    "for index, tweet in tweets.iterrows():\n",
    "    f.write(f'{random.choice(user_ids)},{tweet[\"tweetId\"]},POSTED\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///posted.csv' AS row MATCH (u:User {userId: row.userId}) MATCH (t:Tweet {tweetId: row.tweetId}) MERGE (u)-[:POSTED]->(t)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = conn.query(\"MATCH (a)-[:FOLLOWS]->(b) RETURN b, COUNT(a) as followers ORDER BY followers DESC LIMIT 100\")\n",
    "allTweets = conn.query(\"Match (t: Tweet) RETURN t\");\n",
    "f = open(\"import/likes.csv\",\"w\")\n",
    "f.write(\"userId,tweetId,:TYPE\\n\")\n",
    "\n",
    "for user in top100: \n",
    "    followers = conn.query(f\"MATCH (follower:User)-[:FOLLOWS]->(following:User) WHERE following.userId ='{user['b']['userId']}' RETURN follower\")\n",
    "    tweets = conn.query(f\"MATCH (u:User {{userId: '{user['b']['userId']}'}})-[:POSTED]->(t:Tweet) RETURN t\");\n",
    "    for tweet in tweets: \n",
    "        for follower in followers:\n",
    "            shouldLike = random.random() < 0.1\n",
    "            if shouldLike:\n",
    "                f.write(f\"{follower['follower']['userId']},{tweet['t']['tweetId']},LIKES\\n\")\n",
    "\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "conn.query(\"LOAD CSV WITH HEADERS FROM 'file:///likes.csv' as row CALL { with row MATCH (u:User {userId: row.userId}) MATCH (t:Tweet {tweetId: row.tweetId}) MERGE (u)-[:LIKES]->(t) }  IN TRANSACTIONS OF 100000 ROWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 User mit den meisten Followern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user23516 :  3383\n",
      "user25074 :  3216\n",
      "user1781 :  2735\n",
      "user50940 :  2647\n",
      "user69469 :  2471\n",
      "user40743 :  2462\n",
      "user33433 :  2133\n",
      "user38752 :  2074\n",
      "user14303 :  1905\n",
      "user29918 :  1707\n",
      "user73980 :  1632\n",
      "user31252 :  1591\n",
      "user56892 :  1521\n",
      "user56971 :  1503\n",
      "user66477 :  1500\n",
      "user77339 :  1410\n",
      "user77394 :  1402\n",
      "user4665 :  1370\n",
      "user21904 :  1337\n",
      "user58114 :  1315\n",
      "user47959 :  1273\n",
      "user45639 :  1255\n",
      "user71012 :  1231\n",
      "user19416 :  1214\n",
      "user1733 :  1201\n",
      "user18127 :  1198\n",
      "user58309 :  1186\n",
      "user52387 :  1167\n",
      "user63035 :  1154\n",
      "user27752 :  1123\n",
      "user77284 :  1120\n",
      "user64715 :  1108\n",
      "user33440 :  1098\n",
      "user77008 :  1088\n",
      "user76017 :  1072\n",
      "user80101 :  1070\n",
      "user10026 :  1059\n",
      "user19035 :  1053\n",
      "user60306 :  1047\n",
      "user11550 :  1036\n",
      "user41077 :  1022\n",
      "user65544 :  1016\n",
      "user23821 :  1014\n",
      "user31073 :  992\n",
      "user54692 :  989\n",
      "user35681 :  977\n",
      "user40788 :  957\n",
      "user74879 :  928\n",
      "user25302 :  920\n",
      "user115 :  915\n",
      "user27502 :  915\n",
      "user77805 :  913\n",
      "user24501 :  911\n",
      "user47582 :  900\n",
      "user38931 :  894\n",
      "user66649 :  889\n",
      "user34800 :  884\n",
      "user35707 :  865\n",
      "user3735 :  859\n",
      "user74324 :  852\n",
      "user44608 :  852\n",
      "user79737 :  844\n",
      "user62554 :  839\n",
      "user21154 :  831\n",
      "user74556 :  818\n",
      "user61486 :  813\n",
      "user53515 :  793\n",
      "user76560 :  786\n",
      "user3786 :  784\n",
      "user61335 :  778\n",
      "user12390 :  761\n",
      "user70373 :  754\n",
      "user47646 :  750\n",
      "user5521 :  750\n",
      "user73512 :  750\n",
      "user4008 :  749\n",
      "user3021 :  747\n",
      "user41327 :  743\n",
      "user21408 :  743\n",
      "user74550 :  738\n",
      "user72024 :  737\n",
      "user55111 :  736\n",
      "user19033 :  736\n",
      "user275 :  735\n",
      "user77864 :  732\n",
      "user36233 :  731\n",
      "user64371 :  730\n",
      "user68699 :  728\n",
      "user42799 :  714\n",
      "user71040 :  712\n",
      "user79423 :  710\n",
      "user60891 :  709\n",
      "user78019 :  697\n",
      "user69670 :  683\n",
      "user3856 :  679\n",
      "user69248 :  672\n",
      "user44466 :  672\n",
      "user8644 :  669\n",
      "user24659 :  666\n",
      "user63334 :  665\n"
     ]
    }
   ],
   "source": [
    "top100 = conn.query(\"MATCH (a)-[:FOLLOWS]->(b) RETURN b, COUNT(a) as followers ORDER BY followers DESC LIMIT 100\")\n",
    "\n",
    "for user in top100:\n",
    "    print(user['b']['name'], \"hat\", user['followers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 100 User, die den meisten Userns der Top 100 folgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"MATCH (follower:User)-[follows:FOLLOWS]->(followed:User)\n",
    "WHERE followed.userId IN [\"\"\" \n",
    "\n",
    "count = 0\n",
    "for user in top100:\n",
    "    query += f\"'{user['b']['userId']}'\"\n",
    "    if count < 99: query += \",\"\n",
    "    count += 1\n",
    "\n",
    "query += \"\"\"]\n",
    "WITH follower, COUNT(follows) AS numFollowed\n",
    "ORDER BY numFollowed DESC\n",
    "RETURN follower.name AS username, numFollowed\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "result = conn.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user14303 folgt 69 Usern\n",
      "user41327 folgt 55 Usern\n",
      "user2169 folgt 50 Usern\n",
      "user41320 folgt 49 Usern\n",
      "user33440 folgt 47 Usern\n",
      "user64029 folgt 46 Usern\n",
      "user29265 folgt 44 Usern\n",
      "user38908 folgt 41 Usern\n",
      "user29314 folgt 40 Usern\n",
      "user36591 folgt 39 Usern\n",
      "user12499 folgt 38 Usern\n",
      "user33065 folgt 38 Usern\n",
      "user74270 folgt 37 Usern\n",
      "user21544 folgt 37 Usern\n",
      "user51566 folgt 37 Usern\n",
      "user29427 folgt 36 Usern\n",
      "user67590 folgt 35 Usern\n",
      "user71341 folgt 35 Usern\n",
      "user66389 folgt 35 Usern\n",
      "user41077 folgt 35 Usern\n",
      "user61428 folgt 34 Usern\n",
      "user38931 folgt 34 Usern\n",
      "user46348 folgt 34 Usern\n",
      "user64184 folgt 34 Usern\n",
      "user12403 folgt 34 Usern\n",
      "user37319 folgt 34 Usern\n",
      "user76560 folgt 33 Usern\n",
      "user31252 folgt 33 Usern\n",
      "user3856 folgt 33 Usern\n",
      "user68699 folgt 33 Usern\n",
      "user78174 folgt 31 Usern\n",
      "user20319 folgt 31 Usern\n",
      "user4283 folgt 31 Usern\n",
      "user11039 folgt 31 Usern\n",
      "user54856 folgt 31 Usern\n",
      "user34702 folgt 30 Usern\n",
      "user29803 folgt 30 Usern\n",
      "user48178 folgt 30 Usern\n",
      "user21179 folgt 30 Usern\n",
      "user1733 folgt 30 Usern\n",
      "user24086 folgt 30 Usern\n",
      "user73512 folgt 29 Usern\n",
      "user72950 folgt 29 Usern\n",
      "user26324 folgt 29 Usern\n",
      "user25095 folgt 29 Usern\n",
      "user59825 folgt 29 Usern\n",
      "user6668 folgt 29 Usern\n",
      "user45330 folgt 28 Usern\n",
      "user66649 folgt 28 Usern\n",
      "user41345 folgt 28 Usern\n",
      "user77284 folgt 28 Usern\n",
      "user51021 folgt 28 Usern\n",
      "user54709 folgt 28 Usern\n",
      "user14291 folgt 28 Usern\n",
      "user81022 folgt 27 Usern\n",
      "user29675 folgt 27 Usern\n",
      "user53386 folgt 27 Usern\n",
      "user61829 folgt 27 Usern\n",
      "user13672 folgt 27 Usern\n",
      "user77394 folgt 27 Usern\n",
      "user61335 folgt 27 Usern\n",
      "user55891 folgt 27 Usern\n",
      "user34618 folgt 27 Usern\n",
      "user45745 folgt 27 Usern\n",
      "user786 folgt 27 Usern\n",
      "user3414 folgt 27 Usern\n",
      "user18095 folgt 26 Usern\n",
      "user14755 folgt 26 Usern\n",
      "user23821 folgt 26 Usern\n",
      "user78 folgt 26 Usern\n",
      "user31918 folgt 26 Usern\n",
      "user16279 folgt 26 Usern\n",
      "user59746 folgt 26 Usern\n",
      "user40788 folgt 26 Usern\n",
      "user15832 folgt 26 Usern\n",
      "user9204 folgt 26 Usern\n",
      "user10698 folgt 26 Usern\n",
      "user74462 folgt 25 Usern\n",
      "user16401 folgt 25 Usern\n",
      "user63690 folgt 25 Usern\n",
      "user45603 folgt 25 Usern\n",
      "user67336 folgt 25 Usern\n",
      "user50589 folgt 25 Usern\n",
      "user39028 folgt 25 Usern\n",
      "user60340 folgt 25 Usern\n",
      "user25283 folgt 25 Usern\n",
      "user65954 folgt 25 Usern\n",
      "user10987 folgt 25 Usern\n",
      "user8475 folgt 25 Usern\n",
      "user71689 folgt 25 Usern\n",
      "user46963 folgt 25 Usern\n",
      "user16488 folgt 25 Usern\n",
      "user25264 folgt 25 Usern\n",
      "user70901 folgt 24 Usern\n",
      "user71202 folgt 24 Usern\n",
      "user275 folgt 24 Usern\n",
      "user35044 folgt 24 Usern\n",
      "user65176 folgt 24 Usern\n",
      "user10210 folgt 24 Usern\n",
      "user80357 folgt 24 Usern\n"
     ]
    }
   ],
   "source": [
    "for record in result:\n",
    "    print(record['username'], \"folgt\", record['numFollowed'], 'Usern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alle Posts eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_user = random.choice(top100)\n",
    "\n",
    "result = conn.query(f\"MATCH (u:User {{name: '{random_user['b']['name']}'}})-[:POSTED]->(t:Tweet) RETURN t\")\n",
    "for tweet in result:\n",
    "    continue\n",
    "    #print(tweet['t']['content'])\n",
    "    #print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anzahl der Follower eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Record followerCount=749>]\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(f\"MATCH (follower:User)-[:FOLLOWS]->(user:User {{name: '{random_user['b']['name']}'}}) RETURN count(follower) AS followerCount\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anzahl der verfolgten Accounts eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Record followedCount=105>]\n",
      "10228272\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(f\"MATCH (user:User {{name: '{random_user['b']['name']}'}})-[:FOLLOWS]->(followed:User) RETURN count(followed) AS followedCount\")\n",
    "print(result)\n",
    "print(random_user['b']['userId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die 25 meistgeliketen Posts der gefolgten Accounts eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Roots album avail now!! \n",
      "https://t.co/rJdXrSyYr5‚Ä¶ http://t.co/fYjdt2dxN8\n",
      "Likes:  3668\n",
      "\n",
      "@tariqterry bb I travel\n",
      "Likes:  3507\n",
      "\n",
      "Eu tento responder a quantas posso. @babihsd @Cristiano perdi a sess√£o de perguntas e respostas? N√£o creio! Faz de novo!\n",
      "Likes:  3501\n",
      "\n",
      "We‚Äôll have the Santa Roll with a side of Miso. https://t.co/npP7r4j1Ms https://t.co/MQlhBx32WH\n",
      "Likes:  3474\n",
      "\n",
      ".@skyferreira's setting the world record for use of lazers on our show tonight. Tune in. #FallonTonight\n",
      "Likes:  3447\n",
      "\n",
      "üí≠ http://t.co/9Q6v0Znn4N\n",
      "Likes:  3399\n",
      "\n",
      "I saved a piece of birthday cake my fans. You made my 20s worth it all.  To spreading love, above all things. ‚ù§Ô∏èüåé https://t.co/69Z2JX4ylt\n",
      "Likes:  3387\n",
      "\n",
      "So interesting. @BillGates is on our program this evening. Fun. #GatesLetterDOTCOM\n",
      "Likes:  3132\n",
      "\n",
      "Let me hear u #ScreamingAndShouting with tweets if u downloaded the song on iTunes... feeling it people?? http://t.co/kaRLNR2W\n",
      "Likes:  3058\n",
      "\n",
      "Lady Gaga and @ladystarlightny raid the floors of #affleckspalace  We've been a duo for almost 10‚Ä¶ http://t.co/dYa9hrNUyn\n",
      "Likes:  2928\n",
      "\n",
      "Roses. http://t.co/NWBJF03C7W\n",
      "Likes:  2856\n",
      "\n",
      "What a great day at the skate park looks like!! Thanks @AlexMidler @Volcom @RealSkateboards for making it so special! http://t.co/frvbKb9gkl\n",
      "Likes:  2850\n",
      "\n",
      "‚ÄúEvery time I look at one of the drawings, they make me smile, and I think we need more of that.‚Äù ‚Äî@MarieMcG23 https://t.co/KOWVfW0vzQ\n",
      "Likes:  2841\n",
      "\n",
      "Made buckwheat crepes this morning (and by morning, I mean 1pm when I woke up) http://t.co/AdiYY2dg\n",
      "Likes:  2829\n",
      "\n",
      "I üíó you @maryjblige!!\n",
      "Likes:  2808\n",
      "\n",
      "I'm SO POWERED UP #artRAVESeoul get ready to rage tonight! üíé &amp; üíä\n",
      "Likes:  2799\n",
      "\n",
      "Playing \"Word Sneak\" with the hilarious Martin Short http://t.co/6QRSoZRrlu #FallonTonight\n",
      "Likes:  2796\n",
      "\n",
      "I've done everything I could to the best of my ability. Thank you for the unconditional love and cyber‚Ä¶ http://t.co/Q4LLTjuOVL\n",
      "Likes:  2787\n",
      "\n",
      "The Week on Instagram | 209 \n",
      "https://t.co/uBAxE1fBfs https://t.co/WNIObsuX34\n",
      "Likes:  2781\n",
      "\n",
      "A fire broke out Monday at Florida mosque where the Pulse nightclub shooter, Omar Mateen, used to pray. https://t.co/0d4PZ6Nxu0\n",
      "Likes:  2772\n",
      "\n",
      "Happy birthday, @JimmyFallon! I had so much fun beating you in our lip sync battle. B!@#$ better have my trophy. Sending love.\n",
      "Likes:  2763\n",
      "\n",
      "Thank you for the Trend Monsters, was really sweet. üíó Resting up for the show tonight. ArtRave #44 and dreaming of Tony and #cheektocheek\n",
      "Likes:  2751\n",
      "\n",
      "Happy 4th of July, America!\n",
      "\n",
      "--The Timberlakes https://t.co/N6MPAEwFMo\n",
      "Likes:  2736\n",
      "\n",
      "Oh my goodness, still in shock from this AM. So cool!!! http://t.co/bUVGR9cCuA\n",
      "Likes:  2733\n",
      "\n",
      "@isayuhhi all day\n",
      "Likes:  2721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(f\"\"\"\n",
    "MATCH (follower:User)-[:FOLLOWS]->(followed:User)-[:POSTED]->(tweet:Tweet)\n",
    "WHERE follower.name = '{random_user['b']['name']}'\n",
    "WITH follower, collect(followed.name) AS followedUsers\n",
    "MATCH (t:Tweet)<-[:POSTED]-(u:User)\n",
    "WHERE u.name IN followedUsers\n",
    "OPTIONAL MATCH (t)<-[:LIKES]-(liker:User)\n",
    "RETURN t.content AS content, COUNT(liker) AS numLikes\n",
    "ORDER BY numLikes DESC\n",
    "LIMIT 25\n",
    "\"\"\")\n",
    "\n",
    "for tweet in result:\n",
    "    print(tweet['content'])\n",
    "    print(\"Likes: \", tweet['numLikes'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die 25 neuesten Posts der gefolgten Accounts eines zuf√§lligen Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÄúTo sit back and let fate play its hand out and never influence it is not the way man was meant to operate.‚Äù https://t.co/U7cUApqcz7\n",
      "Tweeted on:  31/12/2016 23:30\n",
      "\n",
      "\"Don‚Äôt count the days; make the days count.\" https://t.co/uiedUxLbg4\n",
      "Tweeted on:  31/12/2016 22:37\n",
      "\n",
      "Gracias a todos por regalarme un a√±o m√°s disfrutando de hacer m√∫sica y comparti√©ndola con ustedes! Mucha paz y aleg‚Ä¶ https://t.co/B7xJ7YNs7m\n",
      "Tweeted on:  31/12/2016 22:26\n",
      "\n",
      "\"Despite everything, no one can dictate who you are to other people.\" https://t.co/Vw9cZsFGqI\n",
      "Tweeted on:  31/12/2016 21:32\n",
      "\n",
      "peace 2016 \n",
      "and thank you ‚úåüèºÔ∏è\n",
      "‚òÑÔ∏èüôèüèº‚ô° \n",
      "we're gonna be alright üí´üí°\n",
      "‚ô° üêá https://t.co/WtuXfwutzU\n",
      "Tweeted on:  31/12/2016 20:38\n",
      "\n",
      "In 2016, #ThisHappened https://t.co/6pZjo8fylG\n",
      "Tweeted on:  31/12/2016 18:26\n",
      "\n",
      "In 2016, #ThisHappened https://t.co/6pZjo8fylG\n",
      "Tweeted on:  31/12/2016 18:26\n",
      "\n",
      "From Rio to Euro and everything in between. These were the most talked about trends around the globe in 2016.\n",
      "https://t.co/LQJNkKE8of\n",
      "Tweeted on:  31/12/2016 17:34\n",
      "\n",
      "From Rio to Euro and everything in between. These were the most talked about trends around the globe in 2016.\n",
      "https://t.co/LQJNkKE8of\n",
      "Tweeted on:  31/12/2016 17:34\n",
      "\n",
      "Who's got Chantaje on their @Spotify NYE playlist for tonight? Let us know where you‚Äôre partying! ShakHQ https://t.co/EAtARlrG6F\n",
      "Tweeted on:  31/12/2016 14:51\n",
      "\n",
      "#DailyFluff\n",
      "https://t.co/LUvfxwzfNl üêæ https://t.co/nyl0tkxdOG\n",
      "Tweeted on:  31/12/2016 12:03\n",
      "\n",
      "#DailyFluff\n",
      "https://t.co/LUvfxwzfNl üêæ https://t.co/nyl0tkxdOG\n",
      "Tweeted on:  31/12/2016 12:03\n",
      "\n",
      "you just got knocked the fuck out\n",
      "Tweeted on:  31/12/2016 06:23\n",
      "\n",
      "üéºüéºüéº YEEZY YEEZY YEEZY NEW SONG ABOUT TO DROP #FACTS üî•üî•üî•\n",
      "Tweeted on:  31/12/2015 23:58\n",
      "\n",
      "üéºüéºüéº YEEZY YEEZY YEEZY NEW SONG ABOUT TO DROP #FACTS üî•üî•üî•\n",
      "Tweeted on:  31/12/2015 23:58\n",
      "\n",
      "üéøthank you to our fans and loved ones who bless us with so much each year. We had a beautiful‚Ä¶ https://t.co/SRgCNbo2ob\n",
      "Tweeted on:  31/12/2015 23:13\n",
      "\n",
      "Ameowzing. Get it ‚Ä¶ aMEOWzing. Oh, Zing! https://t.co/7O5QKD8blT https://t.co/D0lcNw0xSa\n",
      "Tweeted on:  31/12/2015 23:00\n",
      "\n",
      "#RockinEve tonight!! Celebrate with #CONFIDENT on sale for a special price on @AppleMusic üòúüòú https://t.co/UFMTpIsceX https://t.co/Pgh5Y5PiXe\n",
      "Tweeted on:  31/12/2015 21:38\n",
      "\n",
      "NEW YEARS RESOLUTIONS https://t.co/A02mVD067O https://t.co/7zumq6T06S\n",
      "Tweeted on:  31/12/2015 21:30\n",
      "\n",
      "Our family group chat about our 2016 goals is giving me life!!!! #WatchOutWorld\n",
      "Tweeted on:  31/12/2015 20:44\n",
      "\n",
      "Praying for everyone in Dubai!\n",
      "Tweeted on:  31/12/2015 20:41\n",
      "\n",
      "grateful and excited. thank you to my babes for making 2015 so special. I love you I love you sfm. happy New Year's Eve!!!!!!!!!!!!!!!!!!! ‚ú®\n",
      "Tweeted on:  31/12/2015 19:25\n",
      "\n",
      "DEADLINE: Chip in to help fund the fight for more progress in 2016. https://t.co/ezVFTh8LJ2\n",
      "Tweeted on:  31/12/2015 19:24\n",
      "\n",
      "DEADLINE: Chip in to help fund the fight for more progress in 2016. https://t.co/ezVFTh8LJ2\n",
      "Tweeted on:  31/12/2015 19:24\n",
      "\n",
      "Just thought of another New Years resolution.I really want to make my moms life easier &amp; be extra nice! She's the best &amp;does everything 4 us\n",
      "Tweeted on:  31/12/2015 17:05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(f\"\"\"\n",
    "MATCH (follower:User)-[:FOLLOWS]->(followed:User)-[:POSTED]->(tweet:Tweet)\n",
    "WHERE follower.name = '{random_user['b']['name']}'\n",
    "WITH follower, collect(followed.name) AS followedUsers\n",
    "MATCH (t:Tweet)<-[:POSTED]-(u:User)\n",
    "WHERE u.name IN followedUsers\n",
    "RETURN t.content AS content, t.date_time AS date\n",
    "ORDER BY t.date_time DESC\n",
    "LIMIT 25\n",
    "\"\"\")\n",
    "\n",
    "for tweet in result:\n",
    "    print(tweet['content'])\n",
    "    print(\"Tweeted on: \", tweet['date'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching / Fan Out hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die 25 beliebtesten Tweets, die die W√∂rter \"hello\" und \"from\" enthalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did @Adele cross the road? She wanted to say hello from the other side.\n",
      "Likes:  1022\n",
      "\n",
      "You asked: \n",
      "Hello from Japan!\n",
      "I'm Anna!I I'm a big fan! Please say me hello Anna!\n",
      " http://t.co/5Oyi7SiUhY\n",
      "Likes:  394\n",
      "\n",
      "You asked: Can you say hello to me ,please? I am from Bulgaria!!! http://t.co/dyNj55sAq4\n",
      "Likes:  337\n",
      "\n",
      "You asked: Can you say hello to me?  My name is Narin and I am from Germany http://t.co/lx2CRb3xwh\n",
      "Likes:  214\n",
      "\n",
      "#JoanneVibes say hello from backstage at...??? https://t.co/m9PI2oUUo8\n",
      "Likes:  120\n",
      "\n",
      "Say hello to Himanshu Yadav and all my friends from #India. I will come shortly with more news. http://t.co/60xEW67c\n",
      "Likes:  98\n",
      "\n",
      "You asked: Hi Ronaldo! I love you so much! Please say hello to me! I am from Turkey!  http://t.co/xpDH5Ppb67\n",
      "Likes:  87\n",
      "\n",
      "You asked: hello from France, champion ! :) im so proud of you http://t.co/AhDl5iMGzF\n",
      "Likes:  83\n",
      "\n",
      "You asked: hello from morocco \n",
      " http://t.co/gbuEyP5953\n",
      "Likes:  79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = conn.query(\"\"\"\n",
    "MATCH (t:Tweet)\n",
    "WHERE ALL(word IN [' hello ', ' from '] WHERE t.content CONTAINS word)\n",
    "WITH t\n",
    "MATCH (t)<-[:LIKES]-(liker:User)\n",
    "RETURN t.content AS content, COUNT(liker) AS numLikes\n",
    "ORDER BY numLikes DESC\n",
    "LIMIT 25\n",
    "\"\"\")\n",
    "\n",
    "for tweet in result:\n",
    "    print(tweet['content'])\n",
    "    print(\"Likes: \", tweet['numLikes'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
